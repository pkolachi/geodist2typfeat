{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SigTyp-st2020-prt1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkolachi/geodist2typfeat/blob/master/exptnbs/sigtyp-st2020-part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nuSUXKKMhvlL",
        "colab": {}
      },
      "source": [
        "%autosave 60\n",
        "%matplotlib inline\n",
        "fpurl   = 'https://raw.githubusercontent.com/sigtyp/ST2020/master/data/train.csv'\n",
        "# the header from the csv is not properly tab-seperated. hence hard-coding\n",
        "header  = ['wals_code', 'name', \n",
        "           'latitude', 'longitude', \n",
        "           'genus', 'family', 'countrycodes', \n",
        "           'features'\n",
        "          ]\n",
        "\n",
        "CVFOLDS = 2   # default: 2 folds\n",
        "N = -1        # default: use all samples \n",
        "K = 5         # default: use only 5 feature classes\n",
        "REPEAT  = -1\n",
        "# turn this on iff running from command-line to test performance across \n",
        "# different values for (CVFOLDS, K, REPEAT) \n",
        "BATCH = False  \n",
        "\n",
        "import itertools as it\n",
        "from collections import Counter, defaultdict\n",
        "from operator    import itemgetter\n",
        "from IPython.display import display as pd_displayHTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ka9wrCHqzQ7J"
      },
      "source": [
        "I hoped the provided train/test dataset is CSV compliant so that loading the dataset is as simple as using *pandas.read_csv*. It turned out not to be the case. The problem is with the header in the provided csv file, which makes inferring the columns using *header=auto* impossible. This is easily handled by hard-coding the column names in the header and skipping the first row when using *pandas.read_csv*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E1o-kKUMp7HD",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q --user pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv(fpurl, sep='\\t', header=None, names=header, \n",
        "                #index_col=0, \n",
        "                 error_bad_lines=True, skiprows=[0])\n",
        "\"\"\"\n",
        "# since this pynb will never be run on the held-out test set\n",
        "if CVFOLDS <= 1:\n",
        "  trnS, tstS = 0, 0   # dummy values for sizes of train and test partitions\n",
        "else:\n",
        "  tstdf = pd.read_csv(tstfpurl, sep='\\t', header=None, names=header, \n",
        "                      error_bad_lines=True, skiprows=[0])\n",
        "  trnS, tstS = df.shape[0], tstdf.shape[0]\n",
        "  df.append(tstdf) \n",
        "\"\"\"\n",
        "featsFull = df.iloc[:,0:-1]\n",
        "clablFull = df.iloc[:,-1]\n",
        "alablInst = Counter(albl for inst in clablFull for albl in inst.split('|'))\n",
        "alablTabl = pd.DataFrame([{'name': n, 'id': i, 'freq': f}\n",
        "                          for i,(n,f) in enumerate(alablInst.most_common())\n",
        "                         ]).set_index('name')\n",
        "alablFull = pd.DataFrame([dict(albl.split('=', 1) for albl in inst.split('|'))\n",
        "                          for inst in clablFull\n",
        "                         ])\n",
        "for incol in ['wals_code', 'name', 'genus', 'family', 'countrycodes']:\n",
        "  featsFull[incol] = featsFull[incol].astype('category')\n",
        "clablFull = clablFull.astype('category')\n",
        "alablFull = alablFull.astype('category')\n",
        "\n",
        "print(featsFull.shape, clablFull.shape, alablFull.shape, alablTabl.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JV9tca5Ay0ks"
      },
      "source": [
        "Let's plot a few simple statistics about the dataset. \n",
        "1.   Histogram of the complex labels in the dataset\n",
        "2.   Scatterplots of genus vs labels, family vs labels and countrycodes vs labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB-n9hQFwzJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clablFull.name\n",
        "clablFull.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y1p-kfcpy0Yc",
        "colab": {}
      },
      "source": [
        "!{sys.executable} -m pip install -q --user seaborn \n",
        "import seaborn as sns\n",
        "def plot_datastats(features, clabels, alabels):\n",
        "  return\n",
        "\n",
        "if not BATCH:\n",
        "  plot_datastats(featsFull, clablFull, alablFull)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hS-ZOx0MZ32p"
      },
      "source": [
        "The dataset is loaded into a DataFrame and seperated into two parts: input features and output labels. \n",
        "\n",
        "We know a few things about the input features like what are categorical features and what are numerical features. So, we encode the different columns in the feats DataFrame accordingly. *Hopefully this matters* when training different classifiers (especially thinking of decision trees). \n",
        "\n",
        "At this point, I'm not looking at best encoding scheme for the labels which are composite labels themselves (more on this later). The training dataset provided has 1109 unique labels for the dataset of 1125 languages. This indicates that there is *an optimal representation* for the label set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pxmCRll3lMr",
        "colab": {}
      },
      "source": [
        "# sub-select data frame to speed-up experiments while debugging\n",
        "import random\n",
        "import numpy as np\n",
        "# because we want sampling without replacement when we work with selected \n",
        "# features classes to test, using random makes statistics across runs \n",
        "# incomparable -- so use a uniform distribution to select feature classes for \n",
        "# comparison across different experiments. \n",
        "# to get robust estimates while testing, use random selection\n",
        "if N < 2 or N > featsFull.shape[0]:\n",
        "  subsid = list(range(featsFull.shape[0]))\n",
        "else:\n",
        "  subsid = list(range(0, featsFull.shape[0], featsFull.shape[0]//N))[:N]\n",
        "\n",
        "if K < 0 or K > alablFull.shape[1]:\n",
        "  subfci = list(range(alablFull.shape[1]))\n",
        "else:\n",
        "  subfci = list(sorted(random.sample(range(alablFull.shape[1]), K)))\n",
        "  #subfci = list(range(0, alablFull.shape[1], alablFull.shape[1]//K))[:K])\n",
        "subfcs = list(alablFull.columns[i] for i in subfci)\n",
        "\n",
        "featsFull_ = featsFull.iloc[subsid,:]\n",
        "clablFull_ = clablFull.iloc[subsid]\n",
        "alablSub_  = alablFull.iloc[subsid,subfci]\n",
        "alablFull_ = alablFull.iloc[subsid,:]\n",
        "\n",
        "print(featsFull_.shape, clablFull_.shape, alablFull_.shape, alablSub_.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJZ0u8vkZ3XB",
        "colab": {}
      },
      "source": [
        "# it is essential to make deep copies of the data in the dataframe when building\n",
        "# the numerical matrices used for classification experiments. \n",
        "# if not, changes to feature matrices w.r.t. encoding categorial variables are \n",
        "# reflected in the original dataframe which results in errors when trying to \n",
        "# re-use the dataframes for other experiments\n",
        "# e.g. lookup in the atomic-label table built above results in errors because \n",
        "# the lookup tries to find fnc=lbl-idx where idx is the category code \n",
        "X   = featsFull_.copy(deep=False)\n",
        "ccs = X.select_dtypes(['category']).columns \n",
        "X[ccs] = X[ccs].apply(lambda x: x.cat.codes)\n",
        "\n",
        "Y = clablFull_.copy(deep=False).cat.codes\n",
        "\n",
        "Y_  = alablFull_.copy(deep=False)\n",
        "ccs = Y_.select_dtypes(['category']).columns\n",
        "Y_[ccs] = Y_[ccs].apply(lambda x: x.cat.codes)\n",
        "\n",
        "subY_ = alablSub_.copy(deep=False)\n",
        "ccs = subY_.select_dtypes(['category']).columns\n",
        "subY_[ccs] = subY_[ccs].apply(lambda x: x.cat.codes)\n",
        "\n",
        "X  = X.to_numpy()\n",
        "Y  = Y.to_numpy()\n",
        "Y_ = Y_.to_numpy()\n",
        "subY_ = subY_.to_numpy()\n",
        "\n",
        "print(X.shape, Y.shape, Y_.shape, subY_.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I28aYTkvm6TI"
      },
      "source": [
        "Let us try a few classifiers using *scikit-learn* at this point. \n",
        "\n",
        "For what it is worth, the accuracies can be worse than a coin flip, considering the sparse label set.\n",
        "\n",
        "\n",
        " features of languages spoken in close proximity and belonging to the same family should be highly informative in predicting the typographical features for a new language. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8GbLxqzoGwwL",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "!{sys.executable} -m pip install -q --user sklearn \n",
        "from sklearn.model_selection import KFold, RepeatedKFold\n",
        "#from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "classifiers = {'knn':    KNeighborsClassifier(),\n",
        "              #'lsvm':   SVC(kernel=\"linear\"),\n",
        "              #'rbfsvm': SVC(gamma=2),\n",
        "              #'gp':     GaussianProcessClassifier(),\n",
        "               'dt':     DecisionTreeClassifier(),\n",
        "               'rf':     RandomForestClassifier(), #default worse than suggested values\n",
        "               'mlp':    MLPClassifier(), #default worse than suggested values\n",
        "               'adb':    AdaBoostClassifier(),\n",
        "               'nb':     GaussianNB(),\n",
        "              #'qda':    QuadraticDiscriminantAnalysis(),\n",
        "               'ridge':  RidgeClassifier(),\n",
        "               '-dumbase-': DummyClassifier(strategy=\"most_frequent\") \n",
        "              }\n",
        "\n",
        "statnames = ['Classifiers', 'Avg. Test-acc', 'Avg. Train-acc', \n",
        "             'Std. Test-acc',  'Std. Train-acc',\n",
        "             'Avg. Test-time', 'Avg. Train-time'\n",
        "            ]\n",
        "statcodes = ['clfn', 'mtsts', 'mtrns', 'vtsts', 'vtrns', 'predt', 'trint']\n",
        "\n",
        "REPEAT  = REPEAT  if REPEAT  >  1 else 1  # sanity-check\n",
        "CVFOLDS = CVFOLDS if CVFOLDS >= 2 else 2  # sanity-check\n",
        "# scikit-learn documentation recommends using StratifiedKFold for classification\n",
        "# problems to preserve class balance across folds. however, in this case, \n",
        "# we use KFold and RepeatedKFold because \n",
        "#  number of items in a class <= CVFOLDS (works only with 2 folds for entire dataset)\n",
        "#  there is not much balance to preserve w.r.t. complex labels\n",
        "cvsplits = list(RepeatedKFold(n_splits=CVFOLDS, \n",
        "                              n_repeats=REPEAT, random_state=20200408\n",
        "                             ).split(X, Y)\n",
        "               )\n",
        "print(len(cvsplits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D-qdcL_F4cmi",
        "colab": {}
      },
      "source": [
        "def plot_accuracies(accdf):\n",
        "  sns.barplot(x=\"Classifiers\", y=\"Avg. Test-acc\", data=accdf)\n",
        "  #ax2 = sns.barplot(x=\"Classifiers\", y=\"Avg. Train accuracy\", data=accdf)\n",
        "  #ax2.set(ylim=(0, 100))\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qWvm2I-2oPwg",
        "colab": {}
      },
      "source": [
        "#%%time\n",
        "from sklearn import model_selection as skms\n",
        "\n",
        "def trainFullClassifiersCV(classifiers, X, Y):\n",
        "  clfaccs = []\n",
        "  for iclf, nclf in enumerate(classifiers):\n",
        "    clfsce = skms.cross_validate(classifiers[nclf], X, Y, cv=cvsplits, \n",
        "                                 return_train_score=True\n",
        "                                )\n",
        "    clfnfo = [nclf, \n",
        "              100*clfsce['test_score'].mean(), 100*clfsce['train_score'].mean(),\n",
        "              100*clfsce['test_score'].std(),  100*clfsce['train_score'].std(),\n",
        "              clfsce['score_time'].mean(), clfsce['fit_time'].mean()\n",
        "             ]\n",
        "    clfaccs.append(dict(zip(statnames, clfnfo)))\n",
        "  return pd.DataFrame(clfaccs)\n",
        "\n",
        "clfaccs = trainFullClassifiersCV(classifiers, X, Y)\n",
        "if not BATCH:\n",
        "  plot_accuracies(clfaccs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t3IC4j3K0_SW",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from sklearn import metrics as skmt\n",
        "\n",
        "def trainIndClassifiersCV(classifiers, X, matY, return_clfinsts=False):\n",
        "  lclfinst  = {}  # table to store classifiers for later use\n",
        "  lclfaccs = np.zeros((matY.shape[-1], len(classifiers), 6))\n",
        "  avgcaccs = []\n",
        "  for iclf, nclf in enumerate(classifiers):\n",
        "    for indY in range(matY.shape[-1]):\n",
        "      clfsce = skms.cross_validate(classifiers[nclf], X, matY[:,indY], cv=cvsplits,\n",
        "                                   return_train_score=True, \n",
        "                                   return_estimator=return_clfinsts\n",
        "                                  )\n",
        "      lclfaccs[indY][iclf] = [100*clfsce['test_score'].mean(), \n",
        "                              100*clfsce['train_score'].mean(), \n",
        "                              100*clfsce['test_score'].std(),  \n",
        "                              100*clfsce['train_score'].std(), \n",
        "                              clfsce['score_time'].mean(), \n",
        "                              clfsce['fit_time'].mean()\n",
        "                             ]\n",
        "      if return_clfinsts:\n",
        "        lclfinst[(nclf, indY)] = clfsce['estimator']\n",
        "    clfnfo = [nclf, \n",
        "              lclfaccs[:,iclf,0].mean(), lclfaccs[:,iclf,1].mean(),\n",
        "              lclfaccs[:,iclf,2].mean(), lclfaccs[:,iclf,3].mean(),\n",
        "              lclfaccs[:,iclf,4].sum(),  lclfaccs[:,iclf,5].sum()\n",
        "             ]\n",
        "    avgcaccs.append(dict(zip(statnames, clfnfo)))\n",
        "  if return_clfinsts:\n",
        "    return (pd.DataFrame(avgcaccs), lclfinst)\n",
        "  else:\n",
        "    return pd.DataFrame(avgcaccs)\n",
        "\n",
        "avgcaccs, lclclfs = trainIndClassifiersCV(classifiers, X, subY_, return_clfinsts=True)\n",
        "if not BATCH:\n",
        "  #print(avgcaccs.round(3).to_markdown(showindex=False))\n",
        "  pd_displayHTML(avgcaccs.style.hide_index())\n",
        "  plot_accuracies(avgcaccs)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fvX9mw94saLx",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "clablSub = ['|'.join('{0}={1}'.format(k,v) for k,v in row.items() if not pd.isna(v))\n",
        "            for row in alablSub.to_dict(orient='records')\n",
        "           ]\n",
        "# sanity check to make sure subset of labels have been properly extracted\n",
        "if all(True if nl=='' or l.find(sf)!=-1 else False\n",
        "       for l,nl in zip(clablFull.values, clablSub) for sf in nl.split('|')):\n",
        "  print('Sanity check passed')\n",
        "else:\n",
        "  print('Sanity check failed')\n",
        "clablSub = pd.Series(clablSub, name=header[-1])\n",
        "subY = clablSub.astype('category').cat.codes\n",
        "subY = subY.to_numpy()\n",
        "sclfaccs = trainFullClassifiersCV(classifiers, X, subY)\n",
        "if not BATCH:\n",
        "  pd_displayHTML(sclfaccs.style.hide_index())\n",
        "  plot_accuracies(sclfaccs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XXQ4O5uXkZHZ",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "def skmt_mlmc_accuracy_score(y_true, y_pred):\n",
        "  \"Classification accuracy for multi-label multi-class problems\"\n",
        "  n_samples = y_true.shape[0]\n",
        "  return sum(1.0 if np.array_equal(y_true[i], y_pred[i]) else 0\n",
        "             for i in range(n_samples)\n",
        "            ) / n_samples\n",
        "\n",
        "def jntTestIndClassifiersCV(classifiers, X, matY, clfinstances=None):\n",
        "  if not clfinstances:\n",
        "    _, clfinstances = trainIndClassifiersCV(classifiers, X, matY, return_clfinsts=True)\n",
        "  trnpids = list(map(itemgetter(0), cvsplits))\n",
        "  tstpids = list(map(itemgetter(1), cvsplits))\n",
        "  predsst = lambda clf,sids: clf.predict(X[sids]).reshape((-1, 1))\n",
        "  jclfaccs = []\n",
        "  for iclf, nclf in enumerate(classifiers):\n",
        "    tstpreds, trnpreds = [], []\n",
        "    for cvid, (trnids,tstids) in enumerate(cvsplits):\n",
        "      indpreds = list(it.starmap(predsst, [(clfinstances[nclf, indY][cvid], tstids)\n",
        "                                            for indY in range(matY.shape[-1])\n",
        "                                          ]))\n",
        "      tstpreds.append(np.hstack(indpreds))\n",
        "      indpreds = list(it.starmap(predsst, [(clfinstances[nclf, indY][cvid], trnids)\n",
        "                                            for indY in range(matY.shape[-1])\n",
        "                                          ]))  \n",
        "      trnpreds.append(np.hstack(indpreds))\n",
        "    \n",
        "    tstaccs = 100*np.array([skmt_mlmc_accuracy_score(matY[sids], preds)\n",
        "                            for sids, preds in zip(tstpids, tstpreds)\n",
        "                           ])\n",
        "    trnaccs = 100*np.array([skmt_mlmc_accuracy_score(matY[sids], preds)\n",
        "                            for sids, preds in zip(trnpids, trnpreds)\n",
        "                           ])\n",
        "    clfnfo = [nclf, tstaccs.mean(), trnaccs.mean(), tstaccs.std(), trnaccs.std()]\n",
        "    jclfaccs.append(dict(zip(statnames, clfnfo)))\n",
        "  return pd.DataFrame(jclfaccs)\n",
        "\n",
        "jclfaccs = jntTestIndClassifiersCV(classifiers, X, subY_, clfinstances=lclclfs)\n",
        "if not BATCH:\n",
        "  pd_displayHTML(jclfaccs.style.hide_index())\n",
        "  plot_accuracies(jclfaccs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sRiNDJVKLrR6"
      },
      "source": [
        "TODO: \n",
        "\n",
        "*   test other encoding schemes (one-hot encoding and rest in scikit-learn) \n",
        "*   hyper-parameter search and pick 3 classifiers\n",
        "*   also pick an optimal encoding scheme\n",
        "*   test some manual feature additions like geographic distances\n",
        "*   also check l1 regularization and see which features matter the most\n",
        "*   DT/RF & MLP seem to have non-convex optimizations or some other random seed initialization. can't replicate results when run multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Crj6TTlZKVtJ",
        "colab": {}
      },
      "source": [
        "Ymlbl = np.zeros((Y.shape[0], alablTabl.shape[0]))\n",
        "filidx = np.array([ (irow, alablTabl.loc['{0}={1}'.format(fcn, lbl), 'id'])\n",
        "                    for irow, row in enumerate(alablFull_.to_dict(orient='records'))\n",
        "                    for fcn, lbl in row.items() if not pd.isna(lbl)\n",
        "                  ])\n",
        "Ymlbl[[filidx[:,0], filidx[:,1]]] = 1\n",
        "\n",
        "subYmlbl = np.zeros((Y.shape[0], alablTabl.shape[0]))\n",
        "filidx = np.array([ (irow, alablTabl.loc['{0}={1}'.format(fcn, lbl), 'id'])\n",
        "                    for irow, row in enumerate(alablSub_.to_dict(orient='records'))\n",
        "                    for fcn, lbl in row.items() if not pd.isna(lbl)\n",
        "                  ])\n",
        "subYmlbl[[filidx[:,0], filidx[:,1]]] = 1\n",
        "print(Ymlbl.shape, subYmlbl.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3eFDaf8sy-b",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "mlblclasfrs = {'knn': KNeighborsClassifier(),\n",
        "               'dt':  DecisionTreeClassifier(),\n",
        "               'rf':  RandomForestClassifier(), #default worse than suggested values\n",
        "               'mlp': MLPClassifier(), #default worse than suggested values\n",
        "               '-dumbase-': DummyClassifier(strategy='most_frequent')\n",
        "              }\n",
        "mlbclfaccs = trainFullClassifiersCV(mlblclasfrs, X, Ymlbl)\n",
        "if not BATCH:\n",
        "  pd_displayHTML(mlbclfaccs.style.hide_index())\n",
        "  plot_accuracies(mlbclfaccs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y7n2fFNpv_pE",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "smlbclaccs = trainFullClassifiersCV(mlblclasfrs, X, subYmlbl)\n",
        "if not BATCH:\n",
        "  pd_displayHTML(smlbclaccs.style.hide_index())\n",
        "  plot_accuracies(smlbclaccs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YdaXBzY6saXL",
        "colab": {}
      },
      "source": [
        "if BATCH:\n",
        "  from math import factorial\n",
        "  ncombr = lambda n,r: factorial(n) // factorial(r) // factorial(n-r)\n",
        "  global cvsplits, classifiers, mblclassifiers\n",
        "  FRACP = 0.1  # test for 10% of possible choices in feature classes \n",
        "  params = ((cvf, reptr, k) for k in range(5, 100, 10)\n",
        "            for cvf in range(2, 6) for reptr in range(1, 4))\n",
        "  params = list(params)[0]\n",
        "  samcount = alablFull.shape[0]\n",
        "  fnccount = alablFull.shape[1]\n",
        "  subsid = list(range(samcount))\n",
        "  expreport = [] \n",
        "  # this is to make sure that this block can be run in standalone mode\n",
        "  featsFull_ = featsFull.iloc[subsid,:]\n",
        "  clablFull_ = clablFull.iloc[subsid]\n",
        "  alablFull_ = alablFull.iloc[subsid,:]\n",
        "\n",
        "  X   = featsFull_.copy(deep=False)\n",
        "  ccs = X.select_dtypes(['category']).columns \n",
        "  X[ccs] = X[ccs].apply(lambda x: x.cat.codes)\n",
        "  X  = X.to_numpy()\n",
        "  \n",
        "  Y = clablFull_.copy(deep=False).cat.codes\n",
        "  Y  = Y.to_numpy()\n",
        "\n",
        "  Y_  = alablFull_.copy(deep=False)\n",
        "  ccs = Y_.select_dtypes(['category']).columns\n",
        "  Y_[ccs] = Y_[ccs].apply(lambda x: x.cat.codes)\n",
        "  Y_ = Y_.to_numpy()\n",
        "  \n",
        "  Ymlbl = np.zeros((X.shape[0], alablTabl.shape[0]))\n",
        "  filidx = np.array([ (irow, alablTabl.loc['{0}={1}'.format(fcn, lbl), 'id'])\n",
        "                    for irow, row in enumerate(alablFull_.to_dict(orient='records'))\n",
        "                    for fcn, lbl in row.items() if not pd.isna(lbl)\n",
        "                   ])\n",
        "  Ymlbl[[filidx[:,0], filidx[:,1]]] = 1\n",
        "\n",
        "  for expparam in params:\n",
        "    cvsplits = list(RepeatedKFold(n_splits=expparam[0], \n",
        "                                  n_repeats=expparam[1], random_state=20200408\n",
        "                                 ).split(X, Y))\n",
        "    expr1 = trainFullClassifiersCV(classifiers, X, Y)\n",
        "    # run experiment using X,Y\n",
        "    expreport.extend(dict(row.items() +\n",
        "                          [('expname', 'fulllbl-dense'), \n",
        "                           ('CVF', expparam[0]),\n",
        "                           ('REPEAT', expparam[1]), \n",
        "                           ('K', expparam[2])\n",
        "                          ])\n",
        "                     for row in expr1.to_dict(orient='records')\n",
        "                    ) \n",
        "    expr2 = trainFullClassifiersCV(mlblclasfrs, X, Ymlbl)\n",
        "    expreport.extend(dict(row.items() +\n",
        "                          [('expname', 'fulllbl-sparse'), \n",
        "                           ('CVF', expparam[0]),\n",
        "                           ('REPEAT', expparam[1]), \n",
        "                           ('K', expparam[2])\n",
        "                          ])\n",
        "                     for row in expr2.to_dict(orient='records')\n",
        "                    ) \n",
        "\n",
        "    choices = ncombr(fnccount, k)\n",
        "    for trial in range(10):  #int(FRACP*choices)\n",
        "      subfci = list(sorted(random.sample(range(fnccount), expparam[2])))\n",
        "      subfcs = list(alablFull.columns[i] for i in subfci)\n",
        "      \n",
        "      alablSub_  = alablFull.iloc[subsid,subfci]\n",
        "\n",
        "      clablSub = ['|'.join('{0}={1}'.format(k,v)\n",
        "                           for k,v in row.items() if not pd.isna(v))\n",
        "                  for row in alablSub_.to_dict(orient='records')\n",
        "                 ]\n",
        "      clablSub = pd.Series(clablSub, name=header[-1])\n",
        "      subY = clablSub.astype('category').cat.codes\n",
        "      subY = subY.to_numpy()\n",
        "\n",
        "      subY_ = alablSub_.copy(deep=False)\n",
        "      ccs = subY_.select_dtypes(['category']).columns\n",
        "      subY_[ccs] = subY_[ccs].apply(lambda x: x.cat.codes)\n",
        "      subY_ = subY_.to_numpy()\n",
        "\n",
        "      subYmlbl = np.zeros((Y.shape[0], alablTabl.shape[0]))\n",
        "      filidx = np.array([ (irow, alablTabl.loc['{0}={1}'.format(fcn, lbl), 'id'])\n",
        "                         for irow, row in enumerate(alablSub_.to_dict(orient='records'))\n",
        "                         for fcn, lbl in row.items() if not pd.isna(lbl)\n",
        "                       ])\n",
        "      subYmlbl[[filidx[:,0], filidx[:,1]]] = 1\n",
        "      \n",
        "      expr1 = trainFullClassifiersCV(classifiers, X, subY)\n",
        "      expreport.extend(dict(row.items() +\n",
        "                            [('expname', 'sublbl-dense'), ('CVF', expparam[0]),\n",
        "                             ('REPEAT', expparam[1]), ('K', expparam[2]),\n",
        "                             ('TRIAL', trial)\n",
        "                            ])\n",
        "                       for row in expr1.to_dict(orient='records')) \n",
        "      \n",
        "      expr2 = trainFullClassifiersCV(mlblclasfrs, X, subYmlbl)\n",
        "      expreport.extend(dict(row.items() +\n",
        "                            [('expname', 'sublbl-sparse'), ('CVF', expparam[0]),\n",
        "                             ('REPEAT', expparam[1]), ('K', expparam[2]),\n",
        "                             ('TRIAL', trial)\n",
        "                            ])\n",
        "                       for row in expr2.to_dict(orient='records')) \n",
        "      \n",
        "      expr3, clfs = trainIndClassifiers(classifiers, X, subY_, return_clfinstances=True)\n",
        "      expreport.extend(dict(row.items() +\n",
        "                            [('expname', 'sublbl-dense-ind'), ('CVF', expparam[0]),\n",
        "                             ('REPEAT', expparam[1]), ('K', expparam[2]),\n",
        "                             ('TRIAL', trial)\n",
        "                            ])\n",
        "                       for row in expr3.to_dict(orient='records')) \n",
        "      \n",
        "      expr4 = jntTestIndClassifiersCV(classifiers, X, subY_, clfs)\n",
        "      expreport.extend(dict(row.items() +\n",
        "                            [('expname', 'sublbl-dense-jnt'), ('CVF', expparam[0]),\n",
        "                             ('REPEAT', expparam[1]), ('K', expparam[2]),\n",
        "                             ('TRIAL', trial)\n",
        "                            ])\n",
        "                       for row in expr4.to_dict(orient='records')) \n",
        "  \n",
        "  expreport.to_html(open('batchexps-results.html', 'w'))\n",
        "  expreport.to_json('batchexps-results.json')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}