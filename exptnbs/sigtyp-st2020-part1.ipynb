{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pkolachi/geodist2typfeat/blob/master/exptnbs/sigtyp-st2020-part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuSUXKKMhvlL"
   },
   "outputs": [],
   "source": [
    "fpurl   = 'https://raw.githubusercontent.com/sigtyp/ST2020/master/data/train.csv'\n",
    "# the header from the csv is not properly tab-seperated. hence hard-coding\n",
    "header  = ['wals_code', 'name', \n",
    "           'latitude', 'longitude', \n",
    "           'genus', 'family', 'countrycodes', \n",
    "           'features'\n",
    "          ]\n",
    "\n",
    "REPEAT  = 1\n",
    "CVFOLDS = 2   # default: 2 folds\n",
    "N = -1        # default: use all samples \n",
    "K = 5         # default: use only 5 feature classes\n",
    "# turn this on iff running from command-line to test performance across \n",
    "# different values for (CVFOLDS, K, REPEAT) \n",
    "BATCH = False  \n",
    "\n",
    "from IPython.display import display as pd_displayHTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ka9wrCHqzQ7J"
   },
   "source": [
    "I hoped the provided train/test dataset is CSV compliant so that loading the dataset is as simple as using *pandas.read_csv*. It turned out not to be the case. The problem is with the header in the provided csv file, which makes inferring the columns using *header=auto* impossible. This is easily handled by hard-coding the column names in the header and skipping the first row when using *pandas.read_csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1o-kKUMp7HD"
   },
   "outputs": [],
   "source": [
    "!pip -q install -U pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv(fpurl, sep='\\t', header=None, names=header, \n",
    "                 error_bad_lines=True, skiprows=[0])\n",
    "\"\"\"\n",
    "# since this pynb will never be run on the held-out test set\n",
    "if CVFOLDS <= 1:\n",
    "  trnS, tstS = 0, 0   # dummy values for sizes of train and test partitions\n",
    "else:\n",
    "  tstdf = pd.read_csv(tstfpurl, sep='\\t', header=None, names=header, \n",
    "                      error_bad_lines=True, skiprows=[0])\n",
    "  trnS, tstS = df.shape[0], tstdf.shape[0]\n",
    "  df.append(tstdf) \n",
    "\"\"\"\n",
    "featsFull = df.iloc[:,0:-1]\n",
    "clablFull = df.iloc[:,-1]\n",
    "alablFull = pd.DataFrame([dict(f.split('=', 1) for f in inst.split('|'))\n",
    "                          for inst in clablFull\n",
    "                         ])\n",
    "print(featsFull.shape, clablFull.shape, alablFull.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JV9tca5Ay0ks"
   },
   "source": [
    "Let's plot a few simple statistics about the dataset. \n",
    "1.   Histogram of the complex labels in the dataset\n",
    "2.   Scatterplots of genus vs labels, family vs labels and countrycodes vs labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1p-kfcpy0Yc"
   },
   "outputs": [],
   "source": [
    "!pip -q install -U seaborn \n",
    "import seaborn as sns\n",
    "def plot_datastats(features, clabels, alabels):\n",
    "  return\n",
    "\n",
    "if not BATCH:\n",
    "  plot_datastats(featsFull, clablFull, alablFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hS-ZOx0MZ32p"
   },
   "source": [
    "The dataset is loaded into a DataFrame and seperated into two parts: input features and output labels. \n",
    "\n",
    "We know a few things about the input features like what are categorical features and what are numerical features. So, we encode the different columns in the feats DataFrame accordingly. *Hopefully this matters* when training different classifiers (especially thinking of decision trees). \n",
    "\n",
    "At this point, I'm not looking at best encoding scheme for the labels which are composite labels themselves (more on this later). The training dataset provided has 1109 unique labels for the dataset of 1125 languages. This indicates that there is *an optimal representation* for the label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJZ0u8vkZ3XB"
   },
   "outputs": [],
   "source": [
    "for incol in ['wals_code', 'name', 'genus', 'family', 'countrycodes']:\n",
    "  featsFull[incol] = featsFull[incol].astype('category')\n",
    "clablFull = clablFull.astype('category')\n",
    "alablFull = alablFull.astype('category')\n",
    "alablTabl = ['{0}={1}'.format(fcn, lbl) for fcn in alablFull.columns\n",
    "            for lbl in alablFull.loc[:,fcn].unique() if not pd.isna(lbl)\n",
    "            ]\n",
    "alablTabl = dict((v,i) for i,v in enumerate(alablTabl))\n",
    "\n",
    "X   = featsFull\n",
    "ccs = featsFull.select_dtypes(['category']).columns \n",
    "X[ccs] = X[ccs].apply(lambda x: x.cat.codes)\n",
    "\n",
    "Y = clablFull.cat.codes\n",
    "\n",
    "Y_  = alablFull\n",
    "ccs = Y_.select_dtypes(['category']).columns\n",
    "Y_[ccs] = Y_[ccs].apply(lambda x: x.cat.codes)\n",
    "\n",
    "X  = X.to_numpy()\n",
    "Y  = Y.to_numpy()\n",
    "Y_ = Y_.to_numpy()\n",
    "print(X.shape, Y.shape, Y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pxmCRll3lMr"
   },
   "outputs": [],
   "source": [
    "# sub-select data frame/matrix to speed-up experiments while debugging\n",
    "import random\n",
    "import numpy as np\n",
    "# because we want sampling without replacement when we work with selected \n",
    "# features classes to test, using random makes statistics across runs \n",
    "# incomparable -- so use a uniform distribution to select feature classes for \n",
    "# comparison across different experiments. \n",
    "# to get robust estimates while testing, use random selection\n",
    "if N < 0 or N > X.shape[0]:\n",
    "  subsid = list(range(X.shape[0]))\n",
    "else:\n",
    "  #subsid = list(sorted(random.sample(range(X.shape[0]), N)))\n",
    "  subsid = list(range(0, X.shape[0], X.shape[0]//N))[:N]\n",
    "if K < 0 or K > Y_.shape[1]:\n",
    "  subfci = list(range(Y_.shape[1]))\n",
    "else:\n",
    "  subfci = list(sorted(random.sample(range(Y_.shape[1]), K)))\n",
    "  #subfci = list(range(0, Y_.shape[1], Y_.shape[1]//K))[:K])\n",
    "subfcs = list(alablFull.columns[i] for i in subfci)\n",
    "\n",
    "featsFull = featsFull.iloc[subsid,:]\n",
    "clablFull = clablFull.iloc[subsid]\n",
    "alablSub  = alablFull.iloc[subsid,subfci]\n",
    "alablFull = alablFull.iloc[subsid,:]\n",
    "\n",
    "X, Y, Y_ = X[subsid,:], Y[subsid], Y_[subsid,:]\n",
    "subY_    = Y_[:,subfci]\n",
    "print(featsFull.shape, clablFull.shape, alablFull.shape, alablSub.shape)\n",
    "print(X.shape, Y.shape, Y_.shape, subY_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I28aYTkvm6TI"
   },
   "source": [
    "Let us try a few classifiers using *scikit-learn* at this point. \n",
    "\n",
    "For what it is worth, the accuracies can be worse than a coin flip, considering the sparse label set.\n",
    "\n",
    "\n",
    " features of languages spoken in close proximity and belonging to the same family should be highly informative in predicting the typographical features for a new language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GbLxqzoGwwL"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip -q install -U sklearn \n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "classifiers = {'knn':    KNeighborsClassifier(),\n",
    "               'lsvm':   SVC(kernel=\"linear\"),\n",
    "              #'rbfsvm': SVC(gamma=2),\n",
    "              #'gp':     GaussianProcessClassifier(),\n",
    "               'dt':     DecisionTreeClassifier(),\n",
    "               'rf':     RandomForestClassifier(), #default worse than suggested values\n",
    "               'mlp':    MLPClassifier(), #default worse than suggested values\n",
    "               'adb':    AdaBoostClassifier(),\n",
    "               'nb':     GaussianNB(),\n",
    "              #'qda':    QuadraticDiscriminantAnalysis(),\n",
    "               'ridge':  RidgeClassifier() \n",
    "              }\n",
    "statnames = ['Classifiers', 'Avg. Test-acc', 'Avg. Train-acc', \n",
    "             'Std. Test-acc',  'Std. Train-acc',\n",
    "             'Avg. Test-time', 'Avg. Train-time'\n",
    "            ]\n",
    "statcodes = ['clfn', 'mtsts', 'mtrns', 'vtsts', 'vtrns', 'predt', 'trint']\n",
    "\n",
    "REPEAT  = REPEAT  if REPEAT  >  1 else 1  # sanity-check\n",
    "CVFOLDS = CVFOLDS if CVFOLDS >= 2 else 2  # sanity-check\n",
    "# scikit-learn documentation recommends using StratifiedKFold for classification\n",
    "# problems to preserve class balance across folds. however, in this case, \n",
    "# we use KFold and RepeatedKFold because \n",
    "#  number of items in a class <= CVFOLDS (works only with 2 folds for entire dataset)\n",
    "#  there is not much balance to preserve w.r.t. complex labels\n",
    "cvsplits = list(RepeatedKFold(n_splits=CVFOLDS, \n",
    "                              n_repeats=REPEAT, random_state=20200408\n",
    "                             ).split(X, Y)\n",
    "               )\n",
    "print(len(cvsplits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-qdcL_F4cmi"
   },
   "outputs": [],
   "source": [
    "def plot_accuracies(accdf):\n",
    "  sns.barplot(x=\"Classifiers\", y=\"Avg. Test-acc\", data=accdf)\n",
    "  #ax2 = sns.barplot(x=\"Classifiers\", y=\"Avg. Train accuracy\", data=accdf)\n",
    "  #ax2.set(ylim=(0, 100))\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWvm2I-2oPwg"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "from collections import defaultdict\n",
    "from sklearn import model_selection as skms\n",
    "\n",
    "def trainFullClassifiersCV(X, Y):\n",
    "  clfaccs = []\n",
    "  for iclf, nclf in enumerate(classifiers):\n",
    "    clfsce = skms.cross_validate(classifiers[nclf], X, Y, cv=cvsplits, \n",
    "                                 return_train_score=True\n",
    "                                )\n",
    "    clfnfo = [nclf, \n",
    "              100*clfsce['test_score'].mean(), 100*clfsce['train_score'].mean(),\n",
    "              100*clfsce['test_score'].std(),  100*clfsce['train_score'].std(),\n",
    "              clfsce['score_time'].mean(), clfsce['fit_time'].mean()\n",
    "             ]\n",
    "    clfaccs.append(dict(zip(statnames, clfnfo)))\n",
    "  return pd.DataFrame(clfaccs)\n",
    "\n",
    "clfaccs = trainFullClassifiersCV(X, Y)\n",
    "if not BATCH:\n",
    "  plot_accuracies(clfaccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3IC4j3K0_SW"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import metrics as skmt\n",
    "\n",
    "def trainIndClassifiersCV(X, matY, return_clfinsts=False):\n",
    "  lclfinst  = {}  # table to store classifiers for later use\n",
    "  lclfaccs = np.zeros((matY.shape[1], len(classifiers), 6))\n",
    "  avgcaccs = []\n",
    "  for iclf, nclf in enumerate(classifiers):\n",
    "    for indY in range(matY.shape[1]):\n",
    "      clfsce = skms.cross_validate(classifiers[nclf], X, matY[:,indY], cv=cvsplits,\n",
    "                                   return_train_score=True, \n",
    "                                   return_estimator=return_clfinsts\n",
    "                                  )\n",
    "      lclfaccs[indY][iclf] = [100*clfsce['test_score'].mean(), \n",
    "                              100*clfsce['train_score'].mean(), \n",
    "                              100*clfsce['test_score'].std(),  \n",
    "                              100*clfsce['train_score'].std(), \n",
    "                              clfsce['score_time'].mean(), \n",
    "                              clfsce['fit_time'].mean()\n",
    "                             ]\n",
    "      if return_clfinsts:\n",
    "        lclfinst[(iclf, indY)] = clfsce['estimator']\n",
    "    clfnfo = [nclf, \n",
    "              lclfaccs[:,iclf,0].mean(), lclfaccs[:,iclf,1].mean(),\n",
    "              lclfaccs[:,iclf,2].mean(), lclfaccs[:,iclf,3].mean(),\n",
    "              lclfaccs[:,iclf,4].sum(),  lclfaccs[:,iclf,5].sum()\n",
    "             ]\n",
    "    avgcaccs.append(dict(zip(statnames, clfnfo)))\n",
    "  # use a constant estimator that always says the labelvalue for any featureclass is n/a\n",
    "  # don't store instances of this dumbase classifier\n",
    "  lclfaccs = np.zeros((matY.shape[1], 6))\n",
    "  for indY in range(matY.shape[1]):\n",
    "    dumbTstAccs = np.array([skmt.accuracy_score(matY[tstids,indY], \n",
    "                                                np.full((tstids.shape[0], 1), -1)\n",
    "                                               )\n",
    "                            for _,tstids in cvsplits\n",
    "                           ])\n",
    "    dumbTrnAccs = np.array([skmt.accuracy_score(matY[trnids,indY],\n",
    "                                                np.full((trnids.shape[0], 1), -1)\n",
    "                                               )\n",
    "                            for trnids,_ in cvsplits\n",
    "                           ])\n",
    "    lclfaccs[indY] = [100*dumbTstAccs.mean(), 100*dumbTrnAccs.mean(), \n",
    "                      100*dumbTstAccs.std(),  100*dumbTrnAccs.std(), \n",
    "                      0, 0\n",
    "                     ]\n",
    "  bclfnfo = ['-dumbase-',  \n",
    "             lclfaccs[:,0].mean(), lclfaccs[:,1].mean(), \n",
    "             lclfaccs[:,2].mean(), lclfaccs[:,3].mean(), \n",
    "             lclfaccs[:,4].sum(),  lclfaccs[:,5].sum()\n",
    "            ]\n",
    "  avgcaccs.append(dict(zip(statnames, bclfnfo)))\n",
    "  if return_clfinsts:\n",
    "    return (pd.DataFrame(avgcaccs), lclfinst)\n",
    "  else:\n",
    "    return pd.DataFrame(avgcaccs)\n",
    "\n",
    "avgcaccs, lclclfs = trainIndClassifiersCV(X, subY_, return_clfinsts=True)\n",
    "if not BATCH:\n",
    "  #print(avgcaccs.round(3).to_markdown(showindex=False))\n",
    "  pd_displayHTML(avgcaccs.round(3).style.hide_index())\n",
    "  plot_accuracies(avgcaccs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvX9mw94saLx"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "clablSub = ['|'.join('{0}={1}'.format(k,v) for k,v in row.items() if not pd.isna(v))\n",
    "            for row in alablSub.to_dict(orient='records')\n",
    "           ]\n",
    "# sanity check to make sure subset of labels have been properly extracted\n",
    "if all(True if nl=='' or l.find(sf)!=-1 else False\n",
    "       for l,nl in zip(clablFull.values, clablSub) for sf in nl.split('|')):\n",
    "  print('Sanity check passed')\n",
    "else:\n",
    "  print('Sanity check failed')\n",
    "clablSub = pd.Series(clablSub, name=header[-1])\n",
    "subY = clablSub.astype('category').cat.codes\n",
    "subY = subY.to_numpy()\n",
    "sclfaccs = trainFullClassifiersCV(X, subY)\n",
    "if not BATCH:\n",
    "  pd_displayHTML(sclfaccs.round(3).style.hide_index())\n",
    "  plot_accuracies(sclfaccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXQ4O5uXkZHZ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def skmt_mlmc_accuracy_score(y_true, y_pred):\n",
    "  \"Classification accuracy for multi-label multi-class problems\"\n",
    "  n_samples = y_true.shape[0]\n",
    "  return sum(1.0 if np.array_equal(y_true[i], y_pred[i]) else 0\n",
    "             for i in range(n_samples)\n",
    "            ) / n_samples\n",
    "\n",
    "def jntTestIndClassifiersCV(X, matY, clfinstances=None):\n",
    "  if not clfinstances:\n",
    "    _, clfinstances = trainIndClassifiersCV(X, matY, return_clfinsts=True)\n",
    "  trncvsplits = [(trnids, trnids) for trnids, tstids in cvsplits] \n",
    "  trnpartsids = [trnids for trnids, tstids in cvsplits]\n",
    "  tstpartsids = [tstids for trnids, tstids in cvsplits]\n",
    "  prediOnSubs = lambda clf,sid: clf.predict(X[sid]).reshape(-1, 1)\n",
    "  jclfaccs = []\n",
    "  for iclf, nclf in enumerate(classifiers):\n",
    "    tstpreds = []\n",
    "    for tstpid, tstids in enumerate(tstpartsids):\n",
    "      tstpreds.append(np.hstack([clfinstances[(iclf, indY)][tstpid].predict(X[tstids]).reshape((-1,1)) for indY in range(matY.shape[1])]))  \n",
    "    trnpreds = []\n",
    "    for trnpid, trnids in enumerate(trnpartsids):\n",
    "      trnpreds.append(np.hstack([clfinstances[(iclf, indY)][trnpid].predict(X[trnids]).reshape((-1,1)) for indY in range(matY.shape[1])]))\n",
    "    tstaccs = 100*np.array([skmt_mlmc_accuracy_score(matY[instids], pred) for instids, pred in zip(tstpartsids, tstpreds)])\n",
    "    trnaccs = 100*np.array([skmt_mlmc_accuracy_score(matY[instids], pred) for instids, pred in zip(trnpartsids, trnpreds)])\n",
    "    clfnfo = [nclf, tstaccs.mean(), trnaccs.mean(), tstaccs.std(), trnaccs.std()]\n",
    "    jclfaccs.append(dict(zip(statnames, clfnfo)))\n",
    "  return pd.DataFrame(jclfaccs)\n",
    "\n",
    "jclfaccs = jntTestIndClassifiersCV(X, subY_, clfinstances=lclclfs)\n",
    "if not BATCH:\n",
    "  pd_displayHTML(jclfaccs.round(3).style.hide_index())\n",
    "  plot_accuracies(jclfaccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRiNDJVKLrR6"
   },
   "source": [
    "TODO: \n",
    "\n",
    "*   multi-label classification \n",
    "*   test other encoding schemes (one-hot encoding vs rest in scikit-learn) \n",
    "*   hyper-parameter search and pick 2 classifiers\n",
    "*   also pick an optimal encoding scheme\n",
    "*   test some manual feature additions like geographic distances\n",
    "*   also check l1 regularization and see which features matter the most\n",
    "*   DT/RF & MLP seem to have non-convex optimizations or some other random seed initialization. can't replicate results when run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Crj6TTlZKVtJ"
   },
   "outputs": [],
   "source": [
    "Ymlbl = np.zeros((Y.shape[0], len(alablTabl)))\n",
    "filidx = np.array([ (irow, alablTabl['{0}={1}'.format(fcn, lbl)])\n",
    "                    for irow, row in enumerate(alablFull.to_dict(orient='records'))\n",
    "                    for fcn, lbl in row.items() if not pd.isna(lbl)\n",
    "                  ])\n",
    "Ymlbl[[filidx[:,0], filidx[:,1]]] = 1\n",
    "\n",
    "subYmlbl = np.zeros((Y.shape[0], len(alablaTbl)))\n",
    "filidx = np.array([ (irow, alablTabl['{0}={1}'.format(fcn, lbl)])\n",
    "                    for irow, row in enumerate(alablSub.to_dict(orient='records'))\n",
    "                    for fcn, lbl in row.items() if not pd.isna(lbl)\n",
    "                  ])\n",
    "subYmlbl[[filidx[:,0], filidx[:,1]]] = 1\n",
    "print(Ymlbl.shape, subYmlbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3eFDaf8sy-b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mlblclasfrs = {'knn':    KNeighborsClassifier(),\n",
    "               'dt':     DecisionTreeClassifier(),\n",
    "               'rf':     RandomForestClassifier(), #default worse than suggested values\n",
    "               'mlp':    MLPClassifier(), #default worse than suggested values\n",
    "              }\n",
    "global classifiers\n",
    "classifiers = mlblclasfrs\n",
    "mlbclfaccs  = trainFullClassifiersCV(X, Ymlbl)\n",
    "if not BATCH:\n",
    "  pd_displayHTML(mlbclfaccs.round(3).style.hide_index())\n",
    "  plot_accuracies(mlbclfaccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7n2fFNpv_pE"
   },
   "outputs": [],
   "source": [
    "global classifiers\n",
    "classifiers = mlblclasfrs\n",
    "smlbclaccs  = trainFullClassifiersCV(X, subYmlbl)\n",
    "if not BATCH:\n",
    "  pd_displayHTML(smlbclaccs.round(3).style.hide_index())\n",
    "  plot_accuracies(smlbclaccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdaXBzY6saXL"
   },
   "outputs": [],
   "source": [
    "if BATCH:\n",
    "  global CVFOLDS, K, REPEAT\n",
    "  global X, Y, Y_, subys\n",
    "  for cvf in range(2, 6):\n",
    "    CVFOLDS = cvf\n",
    "    for reptr in range(1, 3):\n",
    "      REPEAT = reptr\n",
    "      for k in range(5, 100, 10):\n",
    "        K = k"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjtR7r7Gfh2i8YRTD3qWvI",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SigTyp-st2020-prt1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
